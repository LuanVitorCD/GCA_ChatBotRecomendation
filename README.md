# ğŸ“ RecomendaProf

**RecomendaProf** Ã© um sistema de **recomendaÃ§Ã£o inteligente de orientadores de mestrado/doutorado**, desenvolvido em Python.  
Ele combina **busca semÃ¢ntica via clusterizaÃ§Ã£o** com mÃ©tricas de produtividade acadÃªmica, oferecendo recomendaÃ§Ãµes equilibradas entre **afinidade temÃ¡tica** e **experiÃªncia cientÃ­fica**.

---

## ğŸ’¡ VisÃ£o Geral

O sistema utiliza dados extraÃ­dos do **CurrÃ­culo Lattes**, alÃ©m de mÃ©tricas de impacto (DOI, Impact Factor, CiteScore).  
A aplicaÃ§Ã£o foi reimplementada com **Streamlit** para interface grÃ¡fica, **SQLite** como banco de dados (para facilidade de distribuiÃ§Ã£o) e integraÃ§Ã£o com LLMs para refinamento de busca.

---

## ğŸ–¼ï¸ Imagem do projeto rodando
![Exemplo do projeto rodando com dados reais no motor moderno](assets/example_customvariables_results.png)

---

## ğŸ§  Como Funciona a RecomendaÃ§Ã£o

O **Score de Afinidade** Ã© calculado a partir de um pipeline de 3 estÃ¡gios:

1. **Filtragem e ClusterizaÃ§Ã£o (IA)**
   - O texto do projeto do aluno Ã© refinado e lematizado;
   - Algoritmos de clustering (Birch e KMeans) agrupam docentes semanticamente alinhados Ã  pesquisa.

2. **CÃ¡lculo Multifatorial (6 variÃ¡veis)**
   - Para os candidatos filtrados, o sistema calcula scores normalizados em 6 dimensÃµes:
      - **Ãrea** (AderÃªncia temÃ¡tica);
      - **ExperiÃªncia** (Volume de orientaÃ§Ãµes);
      - **EficiÃªncia** (Taxa de conclusÃ£o);
      - **ProduÃ§Ã£o** (Volume bibliogrÃ¡fico);
      - **ColaboraÃ§Ã£o** (Redes de coautoria/bancas);
      - **Pesquisa** (Projetos).

![VariÃ¡veis usadas na recomendaÃ§Ã£o](assets/variables_used.png)

3. **Ranking Final**
- O Ãndice de RecomendaÃ§Ã£o ($IR$) Ã© a soma ponderada dessas variÃ¡veis, com pesos ajustÃ¡veis pelo usuÃ¡rio.


---

## ğŸš€ Funcionalidades

- ExtraÃ§Ã£o e processamento de dados do CurrÃ­culo Lattes;
- Chatbot Inteligente que refina a busca do aluno usando LLMs (Local ou Nuvem);
- Pesos PersonalizÃ¡veis: O aluno define o que Ã© mais importante (ex: focar em produÃ§Ã£o ou em experiÃªncia);
- Explicabilidade: Cada recomendaÃ§Ã£o vem com uma justificativa gerada por IA;
- Sistema de Favoritos e OcultaÃ§Ã£o de candidatos;
- Banco de dados SQLite portÃ¡til, sem necessidade de instalaÃ§Ã£o de servidores complexos.

---

## ğŸ§© Estrutura do Projeto

```bash
.
â”œâ”€â”€ streamlit_app.py        # Interface principal em Streamlit  
â”œâ”€â”€ requirements.txt        # DependÃªncias do projeto
â”œâ”€â”€ .gitignore              # Arquivo git que diz quais arquivos ignorar enviar para versionamento
â”œâ”€â”€ data.zip                # Pasta com os dados, basta extrair
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ base_recomendacao.db   # AparecerÃ¡ pÃ³s extraÃ§Ã£o do ".zip", Ã© um arquivo banco de dados SQLite com dados jÃ¡ inseridos
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€db_utils.py             # ConexÃ£o e utilidades do banco SQLite
â”‚   â””â”€â”€ thesis_recommend.py    # Motor de recomendaÃ§Ã£o (SQLite + k-means + clustering)
â”‚
â””â”€â”€ assets/
    â””â”€â”€ example.png         # Pasta para guardar prints de versÃµes do projeto (facilita na hora de mostra-los no README)
```

---

## ğŸ› ï¸ Tecnologias Utilizadas

- **Python 3.10+**
- **Streamlit** â€” interface web interativa
- **SQLite** â€” banco relacional principal
- **spaCy** â€” processamento de linguagem natural
- **Pandas** â€” manipulaÃ§Ã£o de dados
- **Scikit-learn** â€” cÃ¡lculo de mÃ©tricas e pontuaÃ§Ãµes
- **SQLite3** â€” conexÃ£o com SQLite

---

## âš™ï¸ InstalaÃ§Ã£o

```bash
git clone https://github.com/LuanVitorCD/GCA_ChatBotRecomendation.git
cd GCA_ChatBotRecomendation

python -m venv venv
source venv/bin/activate   # Linux/Mac
venv\Scripts\activate      # Windows
pip install -r requirements.txt

python -m spacy download pt_core_news_md
```

---

## â–¶ï¸ ExecuÃ§Ã£o

### Modo Real (SQLite)
1. Extraia a pasta zipada com o .db `data.zip`;
2. Configure na sidebar:
   - (se selecionado no provedor `Nuvem (Gemini)`) as credenciais de API Gemini que utilizarÃ¡;
   ![Credenciais API](assets/example_geminiapi_key.png)

   - (se selecionado no provedor `Local (Ollama)`) qual o modelo LLM rodando no Ollama que utilizarÃ¡.
   ![Credenciais API](assets/example_ollamalocal_model.png)
   
3. Rode a aplicaÃ§Ã£o:
   ```bash
   streamlit run streamlit_app.py
   ```
4. Digite um prompt com sua Ã¡rea e interesses (ex: â€œGraduado em CiÃªncia da ComputaÃ§Ã£o com interesse em pÃ³s focando em Modelagem MatemÃ¡tica e Machine Learningâ€) e clique em **Recomendar**.

---

## ğŸ‘©â€ğŸ’» Autoria

Projeto de pesquisa em desenvolvimento contÃ­nuo.  
A lÃ³gica do modelo da tese em **Scikit-learn** Ã© fixa, enquanto os mÃ³dulos auxiliares sÃ£o reimplementados em Python para maior flexibilidade e integraÃ§Ã£o moderna.
